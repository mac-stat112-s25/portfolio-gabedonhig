---
title: "Exam 1 Summary"
format: html
---
```{r}
library(tidyverse)
library(sf)
library(maps)
library(mosaic)
library(gplots)
library(leaflet)
library(rnaturalearth)
```
## The Max Number of Variables in a Viz is 7:

 - X-axis
 - Y-axis
 - Opacity
 - Color
 - Size
 - Shape
 - Facets
 - 3 dimensions

## Effective Viz Checklist:

 - Is graph effective?
  - right for data
  - appropriate for story
  - clear purpose
  - appropriate audience
  - unbiased / inclusive
  - not misleading

 - Is graph complete?
  - title
  - subtitle
  - X-axis label
  - X-axis marks
  - Y-axis label
  - Y-axis marks
  - legend title
  - legend labels
  - capition (author, date, source)
  - data labels
  - date annotation

 - Is graph accessible
  - color (fill, border, background, text)
  - alt-text
  - text size

## Steps to an Effective Viz:

 - Identify simple research questions
  - what do you want to understand about the variables or the relationships among them?
 - Start with the basic and work incrementally
  - Identify what variables you want to include in your plot and what structure these have (e.g: categorical,      quantitative, dates)
  - start simply, build a plot of just one of these variables, or the relationship between two of the variables
  - set up a plotting frame and add just one geometric layer at a time
  - start tweaking: add whatever new variables you want to examine
 - Ask your plot questions
  - what questions does your plot answer? What questions are left unanswered by your plot?
  - what new questions does your plot spark/inspire?
  - do you have the visualization tools to answer these questions, or might you learn more?
 - Focus
  - reporting a large number of visualizations can overwhelm the audience and obscure your conclusions.            Instead, pick out a focused yet comprehensive set of visualizations.

## Data in Spreadsheets is Called Tidy When:

 - Each row = a unit of observation
 - Each column = a measure of some variable of interest:
  - quantitative = numbers with units
  - categorical = discrete possibilities or categories
 - Each entry contains a single data value, ie, no analysis, summaries, footnotes, comments, etc. Only one        value per cell

## Bivariate / Multivariate Viz:

In bivariate viz there are two variables. One is an independent variable and one is a dependent variable. You are trying to explain the variability of one variable relative to the other. 

```{r}
elections <- read.csv("https://mac-stat.github.io/data/election_2020_county.csv")

ggplot(elections, aes(x = repub_pct_16, y = repub_pct_20)) +
  geom_point() +
  geom_smooth(method = "lm")
  labs(x = "Percent of Republican Vote in 2016", title = "Republican Vote by County in 2016 vs 2020", y = "Percent of Republican Support in 2020")
```

In multivariate viz, you just use more variables to show the relationship between them.

```{r}
weather <- read.csv("https://mac-stat.github.io/data/weather_3_locations.csv") |> 
  mutate(date = as.Date(date))  

ggplot(weather, aes(y = temp3pm, x = temp9am, color = location)) + 
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm") +
  labs(x = "Temperature at 9 am", title = "Weather observation in Australia",y = "Temperature at 3 pm", color = "Location")
```

## Spatial Viz:

Create a map widget by calling leaflet( ) and telling it the data to use
```{r}
fave_places <- read.csv("https://hash-mac.github.io/stat112site-s25/data/our_fave_places.csv")

leaflet(data = fave_places)
```

Add a base map using addTiles( ) or addProviderTiles( )
```{r}
leaflet(data = fave_places) |> 
  addTiles()
```

Add layers to the map using layer functions(addMarkers( ) or addPolygons( ))
```{r}
leaflet(data = fave_places) |> 
  addTiles() |> 
  addMarkers(lng = ~longitude, lat = ~latitude)
```
Print the map widget to display it


## The 3 Types of Spatial Viz:

Point map: Maps plotting individual observations
```{r}
starbucks <- read.csv("https://mac-stat.github.io/data/starbucks.csv")

ggplot(starbucks, aes(y = Latitude, x = Longitude)) + 
  geom_point(size = 0.5)
```


Contour maps: Maps plotting the density of the distribution of observations
```{r}
starbucks_cma <- starbucks_cma <- starbucks |> 
  filter(Country %in% c('CA', 'MX', 'US'))

cma_boundaries <- ne_states(
  country = c("canada", "mexico", "united states of america"),
  returnclass = "sf")

ggplot(cma_boundaries) + 
  geom_sf() + 
  geom_density_2d(
    data = starbucks_cma,
    aes(x = Longitude, y = Latitude),
    size = 0.2,
    color = "darkgreen"
  ) +
  coord_sf(xlim = c(-179.14, -50), ylim = c(14.54, 83.11)) +
  theme_map()
```


Choropleth maps: Maps plotting outcomes in different regions
```{r}
elections_by_state <-  read.csv("https://mac-stat.github.io/data/election_2020_by_state.csv")
elections_by_counties <- read.csv("https://mac-stat.github.io/data/election_2020_county.csv")

elections_by_state <- elections_by_state |> 
  filter(state_abbr != "DC") |> 
  select(state_name, state_abbr, repub_pct_20) |> 
  mutate(repub_20_categories = 
           cut(repub_pct_20, 
               breaks = seq(30, 70, by = 5), 
               labels = c("30-34", "35-39", "40-44", "45-49",
                          "50-54", "55-59", "60-64", "65-70"), 
               include.lowest = TRUE))

elections_by_counties <- elections_by_counties |> 
  select(state_name, state_abbr, county_name, county_fips,
          repub_pct_20, median_age, median_rent) |> 
  mutate(repub_20_categories = 
           cut(repub_pct_20, 
               breaks = seq(0, 100, by = 10),
               labels = c("0-9", "10-19", "20-29", "30-39", "40-49",
                          "50-59", "60-69", "70-79", "80-89", "90-100"),
               include.lowest = TRUE))

states_map <- map_data("state")

ggplot(elections_by_state, aes(map_id = state_name, fill = repub_pct_20)) +
  geom_map(map = states_map) +
  expand_limits(x = states_map$long, y = states_map$lat) +
  theme_map() +
  labs(fill = "% of Republican Support")
```


## Alt text and titles

Alt text is a written description of the viz that can be read by a screen reader
```{r}
#| fig-alt: "This is a density plot containing a numerical and a categorical variable. The numerical variable in the temperature at 3 pm in Celcius. The categorical variable is the location where the temperature was measured. The numerical variable, the temperature, is on the x-axis. The y-axis represents the density of observations. The density plot has created 3 different lumps, each color coded for the legend which matches them to their location. The Hobart lump rises from 0 degrees celcius to 12.5, where it plateus before falling again at 17.5 and becoming exponentially lower on the y-axis as it approaches 40 degrees celcius on the x-axis. The Uluru lump rises from 10 degrees celcius, and has a series of plataeus followed by elevations until it reaches 37.5 degrees where it begins its decline till it reaches 40 degrees celcius on the x-axis. The Wollongong lump rises rapidly at 12.5 degrees celcius, peaks at 20 degrees celcius, and then rapidly falls till 27.5 degrees celcius where it then has a slightly negative plateuatill 40 degrees celcius."

ggplot(weather, aes(x = temp3pm, fill = location)) + 
  geom_density(alpha = 0.5) + 
  labs(x = "3pm temperature (Celsius)")  
```

The title is a 1-sentence description of a plot
```{r}
#| fig-cap: "Density plots of 3pm temperatures in 3 Australian locations."

ggplot(weather, aes(x = temp3pm, fill = location)) + 
  geom_density(alpha = 0.5) + 
  labs(x = "3pm temperature (Celsius)")  
```

## Categorical plots

**1 variable:**

Bar chart (just counts observations)
```{r}
hikes <- read.csv("https://mac-stat.github.io/data/high_peaks.csv")

ggplot(hikes, aes(x = rating)) +
  geom_bar()
```

**2 variables:**

Bar charts:
  - stacked (heights vary, but each color (stripe) of the bar follows the Y-axis)
```{r}
ggplot(elections, aes(x = historical, fill = winner_20)) +
  geom_bar()
```
  - dodge (side by side)
```{r}
ggplot(elections, aes(x = historical, fill = winner_20)) +
  geom_bar(position = "dodge")
```
  - proportional (all same height)
    - this loses information about the number of observations
```{r}
ggplot(elections, aes(x = historical, fill = winner_20)) +
  geom_bar(position = "fill")
```

**3 variables:**

Facted wrapped bar charts:
  - facet wrapped stacked
```{r}
ggplot(weather, aes(x = raintoday, fill = raintomorrow)) + 
  geom_bar() +
  facet_wrap(~location)
```
  - facet wrapped dodge
```{r}
ggplot(weather, aes(x = raintoday, fill = raintomorrow)) + 
  geom_bar(position = "dodge") +
  facet_wrap(~location)
```
  - facet wrapped proportional
```{r}
ggplot(weather, aes(x = raintoday, fill = raintomorrow)) + 
  geom_bar(position = "fill") +
  facet_wrap(~location)
```

## Numerical Plots:

**1 variable:**

Histogram
```{r}
ggplot(weather, aes(x = maxtemp)) +
  geom_histogram(color = "white")
```

Box plot
```{r}
ggplot(weather, aes(y = maxtemp)) +
  geom_boxplot()
```

Density plot
```{r}
ggplot(weather, aes(x = maxtemp)) +
  geom_density()
```

**2 variables:**

Scatterplot
```{r}
ggplot(weather, aes(x = maxtemp, y = mintemp)) +
  geom_point()
```

Line plot
```{r}
ggplot(weather, aes(x = maxtemp, y = mintemp)) +
  geom_line()
```

**3 variables:**

Scatterplot
  - color
```{r}
ggplot(weather, aes(x = maxtemp, y = mintemp, color = windspeed9am)) +
  geom_point(alpha = 1)
```
  - proportional symbols
```{r}
ggplot(weather, aes(x = maxtemp, y = mintemp, size = rainfall)) +
  geom_point(alpha = 0.5) +
  scale_size_continuous(name = "rainfall", range = c(1, 5))
```
  - opacity
```{r}
ggplot(weather, aes(x = maxtemp, y = mintemp, alpha = windgustspeed)) +
  geom_point()
```

## Mixed Variable Plots:

**1 numerical + 1 categorical:**

Density plots:
  - faceted
```{r}
ggplot(weather, aes(x = windgustspeed)) +
  geom_density() +
  facet_wrap(~location)
```
  - color
```{r}
ggplot(weather, aes(x = windgustspeed, fill = location)) +
  geom_density(alpha = 0.5)
```

Box plot (faceted)
```{r}
ggplot(weather, aes(y = windgustspeed)) +
  geom_boxplot() +
  facet_wrap(~location)
```

Violin
```{r}
ggplot(weather, aes(y = windgustspeed, x = location)) +
  geom_violin()
```
Histograms:
  - faceted
```{r}
ggplot(weather, aes(x = windgustspeed)) +
  geom_histogram(color = "white") +
  facet_wrap(~location)
```
  - fill / color
```{r}
ggplot(weather, aes(x = windgustspeed, fill = location)) +
  geom_histogram(color = "white")
```

**1 numerical + 2 categorical:**

Heat map
```{r}
#| fig-height: 15
#| fig-width: 8
education <- read.csv("https://mac-stat.github.io/data/sat.csv")

plot_data <- education |> 
  column_to_rownames("State") |> 
  data.matrix() |> 
  scale()

heatmap.2(plot_data,
  dendrogram = "none",
  Rowv = NA, 
  scale = "column",
  keysize = 0.7, 
  density.info = "none",
  col = hcl.colors(256), 
  margins = c(10, 20),
  colsep = c(1:7), rowsep = (1:50), sepwidth = c(0.05, 0.05),
  sepcolor = "white", trace = "none"
)
```


**2 numerical + 1 categorical:**

Scatterplots:
  - faceted
```{r}
ggplot(weather, aes(x = mintemp, y = maxtemp)) +
  geom_point() +
  facet_wrap(~location)
```
  - fill / coor
```{r}
ggplot(weather, aes(x = mintemp, y = maxtemp, color = location)) +
  geom_point()
```
  - shape
```{r}
ggplot(weather, aes(x = mintemp, y = maxtemp, shape = location)) +
  geom_point(size = 1, alpha = 0.5)
```
  - labeled points
```{r}
ggplot(weather, aes(x = mintemp, y = maxtemp)) +
  geom_text(aes(label = windgustdir), alpha = 1, size = 2)
```

## Data manipulation

**Piping:**
Use the |> pipe operator. It makes the object on the left side pass to the function on the right to the get a new object.

**Types of reshaped data:**
- Aggregated data
  - Data that has had functions like group_by() or summarize() done to it. It gains aggregate information         about the observations but loses data on individual observations
- Raw data, reshaped
  - Data that is reshaped to maintain individual observations, but in a way that it can be properly               manipulated

**Unit of observation:**
The level at which data is collected and analyzed, by individual cases or groups.

For example, in a dataset of students, each student is the unit of observation. In a dataset of cities, each city is the unit of observation. In a datset of daily weather data, each day is the unit of observation

## Command List:

| Verb             | Outcome                                                                 |
|------------------|-------------------------------------------------------------------------|
| `arrange`        | Arrange the rows according to a variable                                |
| `filter`         | Filter out or obtain a subset of the rows                               |
| `select`         | Select a subset of the columns                                           |
| `mutate`         | Mutate or create a column                                               |
| `summarize`      | Calculate a numerical summary of a column                               |
| `group_by`       | Group the rows by a specified column                                    |
| `ungroup`        | Ungroups the previous `group_by`                                        |
| `count()`        | Counts the number of observations in a group or just the whole column   |
| `n()`            | Also counts the number of observations in a group, but must be used inside of `summarize` or `mutate` |
| `na.rm`          | Makes it so that the expressions you use in your command do not have the `NA` value |
| `as.factor`      | Use it in the `mutate` command to make a variable categorical           |
| `as.numeric`     | Use it in the `mutate` command to make a variable numeric               |
| `head()`         | Shows first rows of dataset                                             |
| `library(package)` | Loads package into program                                            |


**arrange:**

We have dataset weather
```{r}
head(weather)
```
And we use arrange(maxtemp) on it to order observations from lowest to highest value in maxtemp
```{r}
weather |>
  arrange(maxtemp) |>
  head()
```
Or arrange(desc(maxtemp)) to order observations from highest to lowest value in maxtemp
```{r}
weather |>
  arrange(desc(maxtemp)) |>
  head()
```

**filter:**

We can use filter(maxtemp < 45) to get observations with a maxtemp below 45
```{r}
weather |>
  filter(maxtemp < 45) |>
  head()
```

**select:**

We can use select(maxtemp, mintemp, location) to only select those columns
```{r}
weather |>
  select(maxtemp, mintemp, location) |>
  head()
```
Or we can use (-maxtemp) to select all columns except maxtemp
```{r}
weather |>
  select(-maxtemp) |>
  head()
```

**mutate:**

We can use mutate(double_maxtemp = maxtemp * 2) to create a new column
```{r}
weather |>
  mutate(double_maxtemp = maxtemp * 2) |>
  select(maxtemp, mintemp) |>
  head()
```

**summarize:**

We can use summarize(mean_mintemp = mean(mintemp)) to summarize the mintemp column as a mean
```{r}
weather |>
  summarize(mean_mintemp = mean(mintemp, na.rm = TRUE)) |>
  head()
```

**group_by:**

We can use group_by(location) to make the unit of observation location, and then use a function like summarize(avg_mintemp = mean(mintemp))
```{r}
weather |>
  group_by(location) |>
  summarize(avg_mintemp = mean(mintemp, na.rm = TRUE)) |>
  head()
```

**ungroup:**

You can reverse the unit of observation you select in group_by by using ungroup by, but only if you didn't use summarize. In this example, we use group_by(location), then mutate(avg_mintemp = mean(mintemp)), then ungroup()
```{r}
weather |>
  group_by(location) |>
  mutate(avg_mintemp = mean(mintemp, na.rm = TRUE)) |>
  ungroup() |>
  head()
```

**count:**

We have dataset hikes
```{r}
head(hikes)
```

We can use count(rating) to count the number of observations in the location column for each value
```{r}
hikes |>
  count(rating) |>
  head()
```
We can also use count() to count the total observations in the dataset
```{r}
hikes |>
  count() |>
  head()
```

**n:**

We can use n() in a summarize function to count the number of observations in a group, similar to count
```{r} 
hikes <- read.csv("https://mac-stat.github.io/data/high_peaks.csv")

hikes |>
  group_by(rating) |>
  filter(!is.na(rating)) |>
  summarize(total_trails = n())
```

**na.rm:**

We can use na.rm = TRUE in a summarize function to remove all NA values in a column
```{r}
weather |>
  summarize(avg_mintemp = mean(mintemp, na.rm = TRUE))
```

**as.factor:**

We can use as.factor(windgustdir) in a mutate function to make it a factor
```{r}
weather |>
  mutate(windgustdir = as.factor(windgustdir)) |>
  head()
```

**as.numeric:**

We can use as.numeric(mintemp) in a mutate function to make mintemp a number (even though it was already a number)
```{r}
weather |>
  mutate(mintemp = as.numeric(mintemp)) |>
  head()
```

**head():**

We can use head(weather) to check out the first few rows of the weather dataset
```{r}
head(weather)
```

**library():**

When you want to use a package that has been downloaded, use download(the package's name). For example:
```{r}
library(tidyverse)
```


## Logical Operators:

| Operator             | Meaning                              |
|----------------------|---------------------------------------|
| `==`                 | Equal to                              |
| `!=`                 | Not equal to                          |
| `>`                  | Greater than                          |
| `>=`                 | Greater than or equal to              |
| `<`                  | Less than                             |
| `<=`                 | Less than or equal to                 |
| `%in% c(var1, var2)` | Is equal to var1, var2, etc.          |

We can use logical operators to do various things. For example, in data manipulation, you can use it with a filter function like this:
```{r}
weather |>
  filter(mintemp > 0) |>
  head()
```

## Selection Commands:

| Verb                   | Output                                                     |
|------------------------|------------------------------------------------------------|
| `starts_with("string")` | Selects columns that start with the given string            |
| `ends_with("string")`   | Selects columns that end with the given string              |
| `contains("string")`    | Selects columns that contain the given string               |
| `names(dataset1)`       | Returns the names of all columns in the dataset             |
| `is.na`                 | Selects values that are `NA`                                |
| `!is.na`                | Selects values that are **not** `NA`                        |
| `na.omit()`             | Removes rows with any `NA` values from the dataset          |

**starts_with():**

We can use starts_with("wind") in a select function to select columns that start with wind
```{r}
weather |>
  select(starts_with("wind")) |>
  head()
```

**ends_with():**

We can use ends_with("pm") in a select function to select columns of measurements taken in the second half of the day
```{r}
weather |>
  select(ends_with("pm")) |>
  head()
```

**contains():**

We can use contains("3") in a select function to select columns with measurements at 3 pm or am
```{r}
weather |>
  select(contains("3")) |>
  head()
```

**name:**

We can use names(weather) to get the names of each column in the weather dataset
```{r}
names(weather)
```

**is.na():**

We can use is.na(cloud9am) in a filter function to select observations which have NA values in the clouds9am column
```{r}
weather |>
  filter(is.na(cloud9am)) |>
  head()
```

**!is.na():**

We can use !is.na(cloud9am) in a filter function to select observations which don't have NA values in the clouds9am column
```{r}
weather |>
  filter(!is.na(cloud9am)) |>
  head()
```

**na.omit():**

We can use na.omit(weather) to remove all observations with NA values
```{r}
na.omit(weather) |>
  head()
```

## Date Commands:

| Input                        | Output                                              |
|-----------------------------|-----------------------------------------------------|
| `as.Date(today())`          | Returns today’s date                                |
| `year(date)`                | Returns the year from the date                      |
| `month(date)`               | Returns the month (1–12) from the date              |
| `month(date, label = TRUE)` | Returns the month as Jan, Feb, Mar, etc.            |
| `week(date)`                | Returns the week of the year from the date          |
| `mday(date)`                | Returns the day of the month from the date          |
| `yday(date)`                | Returns the day of the year from the date           |
| `wday(date)`                | Returns the day of the week (1 = Sunday by default) |
| `wday(date, label = TRUE)`  | Returns the day of the week as text (e.g. Mon, Tue) |

When you type date1 > date2, you are typing a boolean expression that claims that date 1 occurred after date 2. Same goes for >= and <=

When filtering by dates, use “” marks, or it won’t identify the numbers as a date, for example:
```{r}
weather |>
  filter(date > "2020-05-12") |>
  head()
```

## Reshaping:

You can condense information (pivot longer) to combine information from multiple columns into one. You can also spread information from one column into multiple columns (pivot wider).

| Function                                                                                      | Result                                                                                                                              |
|-----------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------|
| `pivot_wider(names_from = variable1, values_from = variable2)`                                | Creates a new column for each unique value in `variable1`; fills each with values from `variable2`.                                |
| `pivot_longer(cols = c(variable1, variable2, variable3), names_to = "variable4", values_to = "variable5")` | Converts multiple columns into two: `variable4` stores the original column names, `variable5` holds their values.                  |
| `pivot_longer(cols = -c(variable1, variable2, variable3), names_to = "variable4", values_to = "variable5")` | Same as above, but pivots **all columns except** `variable1`, `variable2`, and `variable3`.                                         |

To add a prefix to the name of every new column, use “names_prefix = ‘prefix1’” for pivot_wider at the end of the command. To remove the prefix of the column names in pivot wider, use “names_prefix = ‘prefix2’”. Use it in between names_to and values_to, and it will remove the text (from left to right) in the columns that are combining.

**pivot_wider():**

We can use the pivot_wider() function to create columns for each row, and assign the value of the average maxtemp for each location depending on if it rained or not
```{r}
weather |>
  filter(!is.na(maxtemp)) |>
  filter(!is.na(raintoday)) |>
  group_by(raintoday, location) |>
  summarize(mean_maxtemp = mean(maxtemp)) |>
  pivot_wider(names_from = location, values_from = mean_maxtemp, names_prefix = "avg_maxtemp_")
```

**pivot_longer:**

We can use pivot_longer() to create a column for if the temperature measured in the min or max temp that day, and another column for the value of the mintemp or maxtemp
```{r}
weather |>
  pivot_longer(cols = c(mintemp, maxtemp), names_to = "temp", values_to = "temperature") |>
  select(date, location, temp, temperature) |>
  head()
```

## Joining:

| Function                             | Result                                                                                      |
|--------------------------------------|---------------------------------------------------------------------------------------------|
| `dataset1 |> left_join(dataset2)`    | Adds matching data from `dataset2` to `dataset1`; keeps all rows from `dataset1`.          |
| `dataset1 |> right_join(dataset2)`   | Adds matching data from `dataset1` to `dataset2`; keeps all rows from `dataset2`.          |
| `dataset1 |> inner_join(dataset2)`   | Keeps only rows with matches in **both** datasets; removes rows with no match (no `NA`s).  |
| `dataset1 |> full_join(dataset2)`    | Combines all rows from both datasets; fills with `NA` where there are no matches.          |
| `dataset1 |> anti_join(dataset2)`    | Keeps rows from `dataset1` **that do not match** anything in `dataset2`.                   |
| `dataset1 |> semi_join(dataset2)`    | Keeps rows from `dataset1` **that have a match** in `dataset2`, but includes **only** columns from `dataset1`. |


Inside the join functions, you should specify join_by(commonon_column == common_column) to make sure the right observations are matched together

**left_join:**

We can insert how many students are enrolled in each class by inserting information from the courses_combined dataset into the grades dataset by using left_join()
```{r}
grades <- read.csv("https://mac-stat.github.io/data/grades.csv")

courses <- read.csv("https://mac-stat.github.io/data/courses.csv")

courses_combined <- courses |>
  group_by(sessionID) |>
  summarise(enroll = sum(enroll))

grades |>
  left_join(courses_combined, join_by(sessionID == sessionID)) |>
  head()
```

**right_join:**

We can also add information about grades and student identification number to courses_combined by using right_join(). New observations(rows) will be created in courses_combined to accomodate the larger number of observations in grades
```{r}
grades |>
  right_join(courses_combined, join_by(sessionID == sessionID)) |>
  head()
```

**full_join():**

We can use full_join() between the voters and contact datasets to combine as much information as we can about each observation. However, there will be NA values, meaning that some observations will be missing information for certain columns
```{r}
voters <- data.frame(
  id = c("A", "D", "E", "F", "G"),
  times_voted = c(2, 4, 17, 6, 20)
)
  
contact <- data.frame(
  name = c("A", "B", "C", "D"),
  address = c("summit", "grand", "snelling", "fairview"),
  age = c(24, 89, 43, 38)
)

voters |>
  full_join(contact, join_by(id == name))
```

**inner_join():**

We can use inner_join() between the voters and contact datasets to combine only observations where the combined information will fill all fields, so that no NA values will be created
```{r}
voters |>
  inner_join(contact, join_by(id == name))
```

**anti_join():**

We can use anti_join() to exclude all observations in voters that have a match in contact with no NA values
```{r}
voters |>
  anti_join(contact, join_by(id == name))
```

**semi_join:**

We can use inner_join() between the voters and contact datasets to only show observations in voters where the match in contact has no NA values. This will also not add information to the dataset from contact.
```{r}
voters |>
  semi_join(contact, join_by(id == name))
```

